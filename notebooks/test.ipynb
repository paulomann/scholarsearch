{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmdc/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmdc/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/home/lmdc/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation', 'PROGRAM GUIDED AGENT']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import re\n",
    "from urllib.request import Request\n",
    "from urllib.parse import quote, unquote\n",
    "from typing import Union, List\n",
    "\n",
    "SCHOLAR_URL = \"https://scholar.google.com/scholar?\" \\\n",
    "    + \"hl=en\" \\\n",
    "    + \"&q={query}\"\n",
    "\n",
    "title = \"Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation\"\n",
    "\n",
    "def encode_url(url, params_dict):\n",
    "    for k, v in params_dict.items():\n",
    "        params_dict[k] = quote(v)\n",
    "    return url.format(**params_dict)\n",
    "    \n",
    "\n",
    "class GoogleScholarParser:\n",
    "    \n",
    "    def __init__(self, base_url=SCHOLAR_URL):\n",
    "        self.base_url = base_url\n",
    "        self.http = urllib3.PoolManager()\n",
    "        self.soup = None\n",
    "        \n",
    "    def get_gs_paper_titles(self, page=None):\n",
    "        if page == None:\n",
    "            page = self.soup\n",
    "        if page == None:\n",
    "            return None\n",
    "        paper_titles_h3 = page.find_all(lambda tag: tag.name == \"h3\" and\n",
    "                                        tag.has_key(\"class\") and \"gs_rt\" in tag[\"class\"])\n",
    "        paper_titles = []\n",
    "        for h3_element in paper_titles_h3:\n",
    "            paper_title_a = h3_element.find(lambda tag: tag.name == \"a\")\n",
    "            paper_title = paper_title_a.text\n",
    "            paper_titles.append(paper_title)\n",
    "        return paper_titles\n",
    "\n",
    "    def get_number_of_citations(self, paper_title: str) -> Union[int, None]:\n",
    "        try:\n",
    "            search_url = encode_url(self.base_url, {\"query\": paper_title})\n",
    "            page = self.http.request('GET', search_url)\n",
    "            self.soup = BeautifulSoup(page.data, 'html.parser')\n",
    "            tag = self.soup.find_all(lambda tag: tag.name == \"a\" and \"Cited by\" in tag.text)[0]\n",
    "            print(self.get_gs_paper_titles())\n",
    "            cited_regex_string = \"Cited by (\\d+)\"\n",
    "            regex_match = re.search(cited_regex_string, tag.text)\n",
    "            if regex_match:\n",
    "                return int(regex_match.group(1))\n",
    "        except Exception as e:\n",
    "            print(\"ERROR: \" + repr(e))\n",
    "    \n",
    "    def get_citation_urls(self, paper_title: str):\n",
    "        try:\n",
    "            search_url = encode_url(self.base_url, {\"query\": paper_title})\n",
    "            page = self.http.request('GET', search_url)\n",
    "            self.soup = BeautifulSoup(page.data, 'html.parser')\n",
    "            tag = self.soup.find_all(lambda tag: tag.name == \"a\" and \"Cited by\" in tag.text)[0]\n",
    "            cites_page = self.http.request('GET', \"https://scholar.google.com\"+tag[\"href\"])\n",
    "            cites_soup = BeautifulSoup(cites_page.data, 'html.parser')\n",
    "            print(self.get_gs_paper_titles(cites_soup))\n",
    "        except Exception as e:\n",
    "            print(\"ERROR: \" + repr(e))\n",
    "        \n",
    "gsp = GoogleScholarParser()\n",
    "gsp.get_number_of_citations(title)\n",
    "gsp.get_citation_urls(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
